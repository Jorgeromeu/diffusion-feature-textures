{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch import Tensor\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "\n",
    "from scripts.view_animation_usd import apply_transform_homogeneous, assemble_transform_srt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# translation rotation and scale\n",
    "t = Tensor([1, 2, 3])\n",
    "rotation = Rotation.from_euler('x', 10, degrees=True)\n",
    "r = Tensor(rotation.as_matrix()).T\n",
    "s = 3 * torch.ones(3)\n",
    "\n",
    "# assemble transform matrix\n",
    "tf = assemble_transform_srt(t, s, r)\n",
    "\n",
    "N = 10\n",
    "points = torch.randn(N, 3)\n",
    "\n",
    "# transform with matrix\n",
    "points_transformed_homog = apply_transform_homogeneous(points, tf)\n",
    "\n",
    "# transform manually\n",
    "points_transformed_gt = points.clone()\n",
    "points_transformed_gt = points_transformed_gt * s\n",
    "points_transformed_gt = points_transformed_gt @ r.T\n",
    "points_transformed_gt = points_transformed_gt + t\n",
    "\n",
    "assert torch.allclose(points_transformed_homog, points_transformed_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.view_animation_usd import decompose_transform_srt\n",
    "\n",
    "rotation = Rotation.from_euler(\"x\", 25, degrees=True)\n",
    "\n",
    "# translation rotation and scale\n",
    "t = Tensor([0, 0, 0])\n",
    "r = Tensor(rotation.as_matrix()).T\n",
    "s = 3 * torch.ones(3)\n",
    "\n",
    "# assemble transform matrix\n",
    "tf = assemble_transform_srt(t, s, r)\n",
    "\n",
    "# decompose transform matrix\n",
    "t_, s_, r_ = decompose_transform_srt(tf)\n",
    "\n",
    "# check\n",
    "assert torch.allclose(t, t_)\n",
    "assert torch.allclose(s, s_)\n",
    "assert torch.allclose(r, r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.renderer import FoVPerspectiveCameras\n",
    "\n",
    "# Construct a pytorch3d camera from c2w translation and rotation\n",
    "\n",
    "t = Tensor([0, 0, -3])\n",
    "rot = Tensor(Rotation.from_euler(\"y\", 20, degrees=True).as_matrix())\n",
    "\n",
    "# construct c2w\n",
    "c2w = assemble_transform_srt(t, torch.ones(3), r)\n",
    "\n",
    "# get w2c\n",
    "w2c = c2w.inverse()\n",
    "t_w2c, _, r_w2c = decompose_transform_srt(w2c)\n",
    "\n",
    "# to construct camera pass transposed r_w2c and t_w2c\n",
    "cam = FoVPerspectiveCameras(R=r_w2c.T.unsqueeze(0), T=t_w2c.unsqueeze(0))\n",
    "\n",
    "# recover w2c\n",
    "w2c_ = cam.get_world_to_view_transform().get_matrix()[0].T\n",
    "c2w_ = w2c_.inverse()\n",
    "\n",
    "# recover t and r\n",
    "t_, _, r_ = decompose_transform_srt(c2w_)\n",
    "\n",
    "atol = 0.00001\n",
    "assert torch.allclose(w2c_, w2c, atol=atol)\n",
    "assert torch.allclose(c2w_, c2w, atol=atol)\n",
    "assert torch.allclose(t_, t, atol=atol)\n",
    "assert torch.allclose(r_, r, atol=atol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "texture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
